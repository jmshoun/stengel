{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import stengel.model.pitch_data\n",
    "import stengel.model.pitch_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../data/python/pitch_data_2009.p\", \"rb\") as pitch_file:\n",
    "    pitch_data = stengel.model.pitch_data.PitchData.from_dict(pickle.load(pitch_file))\n",
    "with open(\"../data/python/density_renders.p\", \"rb\") as density_file:\n",
    "    pitch_density = pickle.load(density_file)\n",
    "with open(\"../data/python/compressed_renders.p\", \"rb\") as compressed_density_file:\n",
    "    compressed_density = pickle.load(compressed_density_file)\n",
    "with open(\"../data/python/pitcher_quantiles.p\", \"rb\") as quantile_file:\n",
    "    pitcher_quantiles = pickle.load(quantile_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prep the main pitch data\n",
    "pitch_data.filter_nulls(in_place=True)\n",
    "pitch_counts = pitch_data.pitches_per_pitcher()\n",
    "high_count_pitchers = [i for i, pc in enumerate(pitch_counts) if pc > 3000]\n",
    "pitch_data.filter_by_pitcher_id(high_count_pitchers, in_place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the three types of density arrays we'll be evaluating.\n",
    "density_array = np.array([pitch_density[name].reshape([-1])\n",
    "                          for name in pitch_data.pitchers])\n",
    "density_array = density_array - np.mean(density_array)\n",
    "\n",
    "density_compressed_array = np.array([compressed_density[name].reshape([-1])\n",
    "                                     for name in pitch_data.pitchers])\n",
    "density_compressed_array = density_compressed_array - np.mean(density_compressed_array)\n",
    "\n",
    "quantile_array = np.array([pitcher_quantiles[name].reshape([-1])\n",
    "                          for name in pitch_data.pitchers])\n",
    "quantile_array = (quantile_array - np.mean(quantile_array, axis=0)) / np.std(quantile_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, train_size=0.6, validation_size=0.2, random_seed=1729):\n",
    "    \"\"\"Split a pitch data set into training, validation, and test sets.\"\"\"\n",
    "    train_obs = int(train_size * data.num_observations)\n",
    "    valid_obs = int(validation_size * data.num_observations)\n",
    "    train_indices = np.array(range(train_obs))\n",
    "    valid_indices = np.array(range(train_obs, train_obs + valid_obs))\n",
    "    test_indices = np.array(range(train_obs + valid_obs, data.num_observations))\n",
    "    \n",
    "    data.shuffle()\n",
    "    train_data = data.filter_rows(train_indices, reassign_ids=False)\n",
    "    valid_data = data.filter_rows(valid_indices, reassign_ids=False)\n",
    "    test_data = data.filter_rows(test_indices, reassign_ids=False)\n",
    "    \n",
    "    \n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    scaler.fit(train_data.pitch_data)\n",
    "    train_data.pitch_data = scaler.transform(train_data.pitch_data)\n",
    "    valid_data.pitch_data = scaler.transform(valid_data.pitch_data)\n",
    "    test_data.pitch_data = scaler.transform(test_data.pitch_data)\n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attach_density(data, density_type):\n",
    "    \"\"\"Attach density information to a pitch data set.\"\"\"\n",
    "    if density_type == \"full\":\n",
    "        data.pitch_density = density_array\n",
    "        return data, [1000]\n",
    "    elif density_type == \"compressed\":\n",
    "        data.pitch_density = density_compressed_array\n",
    "        return data, [322]\n",
    "    elif density_type == \"quantile\":\n",
    "        data.pitch_density = quantile_array\n",
    "        return data, [21]\n",
    "    else:\n",
    "        return data, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_parameters(data, hidden_nodes, density_type=\"none\", density_hidden_nodes=None,\n",
    "                        batter_embed_size=None, pitcher_embed_size=None, \n",
    "                        learning_rate=0.1, batch_size=64, train_steps=300000, print_every=5000):\n",
    "    data, density_size = attach_density(data, density_type)\n",
    "    train_data, valid_data, test_data = split_data(data)\n",
    "    \n",
    "    num_batters = len(train_data.batters) if batter_embed_size else None\n",
    "    num_pitchers = len(train_data.pitchers) if pitcher_embed_size else None\n",
    "    model = stengel.model.pitch_outcome.PitchOutcomeModel(\n",
    "        batch_size=batch_size, learning_rate=learning_rate, hidden_nodes=hidden_nodes,\n",
    "        num_batters=num_batters, batter_embed_size=batter_embed_size,\n",
    "        num_pitchers=num_pitchers, pitcher_embed_size=pitcher_embed_size,\n",
    "        density_size=density_size, density_hidden_nodes=density_hidden_nodes\n",
    "    )\n",
    "    model.train(train_data, valid_data, train_steps, print_every)\n",
    "    return model.fit_log, model.fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_summary(eval_results):\n",
    "    \"\"\"Print a friendly, nicely-formatted format of the model results.\"\"\"\n",
    "    eval_names = []\n",
    "    run_times = []\n",
    "    last_run_scores = []\n",
    "    min_run_scores = []\n",
    "    for k, v in eval_results.items():\n",
    "        eval_names.append(k)\n",
    "        run_times.append(v[1])\n",
    "        scores = v[0][\"validation_score\"]\n",
    "        last_run_scores.append(scores[-1])\n",
    "        min_run_scores.append(min(scores))\n",
    "        \n",
    "    eval_names = [x for (s, x) in sorted(zip(last_run_scores, eval_names))]\n",
    "    run_times = [x for (s, x) in sorted(zip(last_run_scores, run_times))]\n",
    "    min_run_scores = [x for (s, x) in sorted(zip(last_run_scores, min_run_scores))]\n",
    "    last_run_scores = sorted(last_run_scores)\n",
    "    \n",
    "    print(\"Model Name                       Fit Time  Best Perp.  Last Perp.\")\n",
    "    print(\"=================================================================\")\n",
    "    for name, time, min_score, last_score in zip(eval_names, run_times, min_run_scores, last_run_scores):\n",
    "        print(\"{:<30}   {:>8.1f}    {:0.3f}    {:0.3f}\".format(name, time, min_score, last_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_basic_structure(data, num_hidden):\n",
    "    return evaluate_parameters(data, num_hidden, train_steps=100000)\n",
    "\n",
    "basic_structure_runs = {\n",
    "    \"No Hidden Layer\": evaluate_basic_structure(pitch_data, []),\n",
    "    \"48-node Hidden Layer\": evaluate_basic_structure(pitch_data, [48]),\n",
    "    \"96-node Hidden Layer\": evaluate_basic_structure(pitch_data, [96]),\n",
    "    \"192-node Hidden Layer\": evaluate_basic_structure(pitch_data, [192]),\n",
    "    \"192x96-node Hidden Layers\": evaluate_basic_structure(pitch_data, [192, 96])\n",
    "}\n",
    "\n",
    "print_summary(basic_structure_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_encodings(data, batter_embed_size, pitcher_embed_size):\n",
    "    return evaluate_parameters(data, [192], batter_embed_size=batter_embed_size,\n",
    "                               pitcher_embed_size=pitcher_embed_size,\n",
    "                               train_steps=150000, print_every=10000)\n",
    "\n",
    "encoding_runs = {\n",
    "    \"Batter Encoding\": evaluate_encodings(pitch_data, 16, None),\n",
    "    \"Pitcher Encoding\": evaluate_encodings(pitch_data, None, 16),\n",
    "    \"Batter and Pitcher Encoding\": evaluate_encodings(pitch_data, 16, 16),\n",
    "    \"Batter and Pitcher Large Encoding\": evaluate_encodings(pitch_data, 32, 32)\n",
    "}\n",
    "\n",
    "print_summary(encoding_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_density(data, density_type):\n",
    "    return evaluate_parameters(data, [192], batter_embed_size=32,\n",
    "                               pitcher_embed_size=32,\n",
    "                               density_type=density_type,\n",
    "                               train_steps=250000, print_every=10000)\n",
    "\n",
    "density_runs = {\n",
    "    \"Full Density\": evaluate_density(pitch_data, \"full\"),\n",
    "    \"Compressed Density\": evaluate_density(pitch_data, \"compressed\"),\n",
    "    \"Quantile Density\": evaluate_density(pitch_data, \"quantile\")\n",
    "}\n",
    "\n",
    "print_summary(density_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_hidden_density(data, hidden_density):\n",
    "    return evaluate_parameters(data, [192], batter_embed_size=16,\n",
    "                               pitcher_embed_size=24, density_hidden_nodes=hidden_density,\n",
    "                               density_type=\"compressed\",\n",
    "                               train_steps=250000, print_every=10000)\n",
    "\n",
    "hidden_density_runs = {\n",
    "    \"Small Hidden\": evaluate_hidden_density(pitch_data, [64]),\n",
    "    \"Big Hidden\": evaluate_hidden_density(pitch_data, [128]),\n",
    "}\n",
    "\n",
    "print_summary(hidden_density_runs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
